{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 6 columns):\n",
      "listing_id       3000 non-null int64\n",
      "id               3000 non-null int64\n",
      "date             3000 non-null object\n",
      "reviewer_id      3000 non-null int64\n",
      "reviewer_name    3000 non-null object\n",
      "comments         2998 non-null object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 140.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1178162</td>\n",
       "      <td>4724140</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>4298113</td>\n",
       "      <td>Olivier</td>\n",
       "      <td>My stay at islam's place was really cool! Good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1178162</td>\n",
       "      <td>4869189</td>\n",
       "      <td>2013-05-29</td>\n",
       "      <td>6452964</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Great location for both airport and city - gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178162</td>\n",
       "      <td>5003196</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>6449554</td>\n",
       "      <td>Sebastian</td>\n",
       "      <td>We really enjoyed our stay at Islams house. Fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       id        date  reviewer_id reviewer_name  \\\n",
       "0     1178162  4724140  2013-05-21      4298113       Olivier   \n",
       "1     1178162  4869189  2013-05-29      6452964     Charlotte   \n",
       "2     1178162  5003196  2013-06-06      6449554     Sebastian   \n",
       "\n",
       "                                            comments  \n",
       "0  My stay at islam's place was really cool! Good...  \n",
       "1  Great location for both airport and city - gre...  \n",
       "2  We really enjoyed our stay at Islams house. Fr...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\gokul\\\\Documents\\\\learning\\\\practise problem\\\\airbnb\\\\Reviews and listings\")\n",
    "reviews = pd.read_csv(\"reviews.csv\").head(3000)\n",
    "\n",
    "reviews.info()\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2998 entries, 0 to 2999\n",
      "Data columns (total 6 columns):\n",
      "listing_id       2998 non-null int64\n",
      "id               2998 non-null int64\n",
      "date             2998 non-null object\n",
      "reviewer_id      2998 non-null int64\n",
      "reviewer_name    2998 non-null object\n",
      "comments         2998 non-null object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 164.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#dropping the empty rows\n",
    "reviews.dropna(inplace=True)\n",
    "reviews.info()\n",
    "\n",
    "#removing the trailing and leading space\n",
    "reviews['comments'] = reviews['comments'].str.strip()\n",
    "\n",
    "#removing the special cahracters\n",
    "reviews['comments'] = reviews['comments'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "#lower case\n",
    "reviews['comments'] = reviews['comments'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [my, stay, at, islam, s, place, was, really, c...\n",
       "1    [great, location, for, both, airport, and, cit...\n",
       "2    [we, really, enjoyed, our, stay, at, islams, h...\n",
       "Name: comments_token, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#token the word\n",
    "import nltk\n",
    "\n",
    "reviews['comments_token']= reviews['comments'].apply(lambda x: x.split())\n",
    "reviews['comments_token'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "reviews['comments_token'] = reviews['comments_token'].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lemma\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def split_lemma(comments):\n",
    "    lemma = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in comments:\n",
    "        a=lemmatizer.lemmatize(word)\n",
    "        lemma.append(a)\n",
    "    return lemma\n",
    "\n",
    "reviews['comments_token']=reviews.apply(lambda row:split_lemma(row['comments_token']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def split_stop_words(message):\n",
    "    stop_words_split = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words_split = ' '.join([word for word in message if word not in stop_words])\n",
    "    return stop_words_split\n",
    "\n",
    "reviews['comments_token_stop']=reviews.apply(lambda row:split_stop_words(row['comments_token']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-033fc3a13ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#visualize the word in wordmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mall_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comments_token'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "#visualize the word in wordmap\n",
    "\n",
    "all_words = ' '.join([text for text in reviews['comments_token']])\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(ngram_range=(1,2), max_df=0.7)\n",
    "tfidf_text = tfidf_vector.fit(reviews['comments_token_stop'])\n",
    "tfidf_total = tfidf_text.transform(reviews['comments_token_stop'])\n",
    "\n",
    "\n",
    "reviews['comments_tfidf'] = tfidf_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-033fc3a13ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#visualize the word in wordmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mall_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comments_token'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "#visualize the word in wordmap\n",
    "\n",
    "all_words = ' '.join([text for text in reviews['comments_token']])\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
